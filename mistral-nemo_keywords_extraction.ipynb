{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b9d6f0-8741-4273-982c-4e8e3f10f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pydantic import BaseModel, Field, ValidationError, field_validator\n",
    "from typing import List, Dict, Any\n",
    "import ast\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e4093b-1147-411b-99dd-74a289f33a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_0/s_2t6l510c3bdxngny7zmfyc0000gn/T/ipykernel_6939/247093999.py:1: DtypeWarning: Columns (8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  listings = pd.read_csv('data/data_uncategorised_Oct21_to_Jan22.csv')\n"
     ]
    }
   ],
   "source": [
    "listings = pd.read_csv('data/data_uncategorised_Oct21_to_Jan22.csv')\n",
    "#listings.head()\n",
    "unique_listings=pd.DataFrame(listings['drug_title'].unique(),columns=['listing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ad5d5a-f3fb-4302-805b-8d0c056482d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_batches(df, batch_size=10):\n",
    "    column_name = df.columns[0]\n",
    "    total_rows = len(df)\n",
    "    results = []\n",
    "\n",
    "    for start in range(0, total_rows, batch_size):\n",
    "        end = min(start + batch_size, total_rows)\n",
    "        batch = df.iloc[start:end]\n",
    "        \n",
    "        batch_result = {str(element): [] for element in batch[column_name]}\n",
    "        results.append(batch_result)\n",
    "\n",
    "    return results\n",
    "\n",
    "class ResponseChecks(BaseModel):\n",
    "    data: Dict[str, List[Any]]\n",
    "    \n",
    "    @field_validator(\"data\")\n",
    "    def check_dict_format(cls, value):\n",
    "        assert isinstance(value, dict), \"Response must be a dictionary\"\n",
    "        assert len(value) > 0, \"Dictionary must not be empty\"\n",
    "        for key, val in value.items():\n",
    "            assert isinstance(val, list), f\"Value for key '{key}' must be a list\"\n",
    "        return value\n",
    "\n",
    "def execute_keyword_LLM(list_of_dicts, chain):\n",
    "    results = []\n",
    "    error_listings = []\n",
    "    total_items = len(list_of_dicts)\n",
    "    \n",
    "    for index, item in enumerate(list_of_dicts, 1):\n",
    "        # Display progress every 10 runs\n",
    "        if index % 10 == 0 or index == total_items:\n",
    "            print(f\"Progress: {index}/{total_items} items processed\")\n",
    "        \n",
    "        try:\n",
    "            response = chain.run(test_data=item)\n",
    "            output = ast.literal_eval(response)\n",
    "            \n",
    "            # Validate the output\n",
    "            ResponseChecks(data=output)\n",
    "            \n",
    "            # If validation passes, add to results\n",
    "            for key, value in output.items():\n",
    "                results.append({\"key\": key, \"value\": value})\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item {index}: {str(e)}\")\n",
    "            error_listings.append(item)\n",
    "            continue\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nProcessing complete.\")\n",
    "    print(f\"Total items: {total_items}\")\n",
    "    print(f\"Successful: {len(list_of_dicts) - len(error_listings)}\")\n",
    "    print(f\"Errors: {len(error_listings)}\")\n",
    "    \n",
    "    return df, error_listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66bb15e8-a319-4770-a01d-22b17d4d69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Break the data frame into batches and convert it to dict for processing\n",
    "list_of_dicts=dataframe_batches(unique_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c615ac7-94d2-464a-8ce6-e0430d36f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = list_of_dicts[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b596825e-c9c9-499e-be2f-5f57a4037832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output formats\n",
    "input_format = r\"\"\"{{\n",
    "  'listing text here': [],\n",
    "  'listing text here': [],\n",
    "  ...\n",
    "}}\"\"\"\n",
    "\n",
    "output_format = r\"\"\"{{\n",
    "  'listing text here': ['keyword1', 'keyword2', ...],\n",
    "  'listing text here': ['keyword1', 'keyword2', ...],\n",
    "  ...\n",
    "}}\"\"\"\n",
    "\n",
    "example_input = r\"\"\"{{\n",
    "  '1 Blister Codein 50mg Codeinium': [],\n",
    "  '65 sample - choose what u want, mix and match': [],\n",
    "  'SPECIAL PROMO: 500x S903-4mg Hulk Bars': [],\n",
    "  '7G L.S.D A+++ TOP PRICES IN UK!!! NDD-FREE POSTAGE': [],\n",
    "  '3.5-56G GREEN CRACKA+++ TOP PRICES IN UK!!! NDD-FREE POSTAGE': [],\n",
    "  'Pure Cocaine 98% purity, 5 grams available': [],\n",
    "  'Acid tabs, blotters, LSD, 25mg each': [],\n",
    "  '50 grams Cannabis buds - premium quality': [],\n",
    "  'Xanax bars, 10mg - pharma grade': [],\n",
    "  'Variety of pills and powders, 100% satisfaction guaranteed': [],\n",
    "  'BD N BSM TEST BUNDLE 1OZ -indoor only- A++': []\n",
    "}}\"\"\"\n",
    "\n",
    "example_output = r\"\"\"{{\n",
    "  '1 Blister Codein 50mg Codeinium': ['Codein', 'Codeinium'],\n",
    "  '65 sample - choose what u want, mix and match': ['NA'],\n",
    "  'SPECIAL PROMO: 500x S903-4mg Hulk Bars': ['S903', 'Hulk Bars'],\n",
    "  '7G L.S.D A+++ TOP PRICES IN UK!!! NDD-FREE POSTAGE': ['LSD'],\n",
    "  '3.5-56G GREEN CRACKA+++ TOP PRICES IN UK!!! NDD-FREE POSTAGE': ['green crack'],\n",
    "  'Pure Cocaine 98% purity, 5 grams available': ['Cocaine'],\n",
    "  'Acid tabs, blotters, LSD, 25mg each': ['Acid', 'LSD'],\n",
    "  '50 grams Cannabis buds - premium quality': ['Cannabis'],\n",
    "  'Xanax bars, 10mg - pharma grade': ['Xanax'],\n",
    "  'Variety of pills and powders, 100% satisfaction guaranteed': ['NA'],\n",
    "  'BD N BSM TEST BUNDLE 1OZ -indoor only- A++': ['BD', 'BSM']\n",
    "}}\"\"\"\n",
    "\n",
    "# Define the template for the prompt\n",
    "template = f\"\"\"Act as an NLP specialist, and your task is to extract keywords from the given substance listings scraped from the dark web. Keywords can include the main item of the listing, and/or any chemical name or compound mentioned, and/or any slang term related to illicit substances. General or common words in the listings like ‘ounces,’ ‘variety,’ ‘after,’ etc., are not considered keywords unless they are part of a recognized slang term. There can be more than 1 keyword in a given listing.\n",
    "\n",
    "Input format:\n",
    "{input_format}\n",
    "\n",
    "Output format:\n",
    "{output_format}\n",
    "\n",
    "Example\n",
    "\n",
    "Input:\n",
    "{example_input}\n",
    "\n",
    "Output:\n",
    "{example_output}\n",
    "\n",
    "Now perform the task on the following and strictly follow the output format and task instructions given above. Remember there can be more than one keywords as well for a given listing. Please don't hallucinate and don't extract imaginary keywords. Listings data:\n",
    "\n",
    "{{test_data}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e43b362-0219-48a3-8e45-b99f20f2d222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanditsadaphale/Library/Caches/pypoetry/virtualenvs/llama-fine-tuning-rZexxVwI-py3.9/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Create a PromptTemplate instance\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"test_data\"])\n",
    "\n",
    "# Initialize the Ollama LLM with the correct model name\n",
    "llm = Ollama(model=\"mistral-nemo\")\n",
    "\n",
    "# Create the LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain with the first element of list_of_dicts\n",
    "#response = chain.run(test_data=list_of_dicts[0])\n",
    "#try:\n",
    "#    output=ast.literal_eval(response)\n",
    "#except:\n",
    "#    output=''\n",
    "#    print('Invalid Response')\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f66ff6b-21f5-43dc-8646-7a6307098402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanditsadaphale/Library/Caches/pypoetry/virtualenvs/llama-fine-tuning-rZexxVwI-py3.9/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10/500 items processed\n",
      "Progress: 20/500 items processed\n",
      "Progress: 30/500 items processed\n",
      "Progress: 40/500 items processed\n",
      "Progress: 50/500 items processed\n",
      "Progress: 60/500 items processed\n",
      "Progress: 70/500 items processed\n",
      "Progress: 80/500 items processed\n",
      "Progress: 90/500 items processed\n",
      "Progress: 100/500 items processed\n",
      "Progress: 110/500 items processed\n",
      "Progress: 120/500 items processed\n",
      "Progress: 130/500 items processed\n",
      "Progress: 140/500 items processed\n",
      "Progress: 150/500 items processed\n",
      "Progress: 160/500 items processed\n",
      "Error processing item 166: 1 validation error for ResponseChecks\n",
      "data\n",
      "  Input should be a valid dictionary [type=dict_type, input_value={\"'50G Sgt-78 #5F-MDMB #C...: ['Replica', 'Carts']\"}, input_type=set]\n",
      "    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\n",
      "Progress: 170/500 items processed\n",
      "Progress: 180/500 items processed\n",
      "Progress: 190/500 items processed\n",
      "Error processing item 193: EOL while scanning string literal (<unknown>, line 2)\n",
      "Error processing item 196: EOL while scanning string literal (<unknown>, line 2)\n",
      "Progress: 200/500 items processed\n",
      "Error processing item 204: EOL while scanning string literal (<unknown>, line 2)\n",
      "Error processing item 207: EOL while scanning string literal (<unknown>, line 2)\n",
      "Progress: 210/500 items processed\n",
      "Error processing item 214: EOL while scanning string literal (<unknown>, line 2)\n",
      "Progress: 220/500 items processed\n",
      "Error processing item 225: EOL while scanning string literal (<unknown>, line 2)\n",
      "Progress: 230/500 items processed\n",
      "Progress: 240/500 items processed\n",
      "Progress: 250/500 items processed\n",
      "Progress: 260/500 items processed\n",
      "Progress: 270/500 items processed\n",
      "Progress: 280/500 items processed\n",
      "Progress: 290/500 items processed\n",
      "Progress: 300/500 items processed\n",
      "Progress: 310/500 items processed\n",
      "Progress: 320/500 items processed\n",
      "Progress: 330/500 items processed\n",
      "Progress: 340/500 items processed\n",
      "Progress: 350/500 items processed\n",
      "Progress: 360/500 items processed\n",
      "Progress: 370/500 items processed\n",
      "Error processing item 377: invalid syntax (<unknown>, line 4)\n",
      "Progress: 380/500 items processed\n",
      "Progress: 390/500 items processed\n",
      "Progress: 400/500 items processed\n",
      "Progress: 410/500 items processed\n",
      "Progress: 420/500 items processed\n",
      "Error processing item 425: EOL while scanning string literal (<unknown>, line 2)\n",
      "Progress: 430/500 items processed\n",
      "Progress: 440/500 items processed\n",
      "Progress: 450/500 items processed\n",
      "Progress: 460/500 items processed\n",
      "Progress: 470/500 items processed\n",
      "Progress: 480/500 items processed\n",
      "Progress: 490/500 items processed\n",
      "Progress: 500/500 items processed\n",
      "\n",
      "Processing complete.\n",
      "Total items: 500\n",
      "Successful: 491\n",
      "Errors: 9\n"
     ]
    }
   ],
   "source": [
    "result_df, errors_df = execute_keyword_LLM(list_of_dicts, chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5e189c9-6c51-4b1f-8721-6d48993c4c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_df.tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21a6dfd0-4c4d-4500-a9ec-a22bc39591df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_folder = 'output'\n",
    "file_name = 'mistral-nemo_10.csv'\n",
    "file_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    result_df.to_csv(file_path, mode='a', header=False, index=False)\n",
    "else:\n",
    "    result_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24faa648-9160-49dc-a84f-251f4ca1f054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89f6e4-dd3b-463f-b019-c4aa92b92877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897eda9-a6f0-4a81-8a91-e92d1ef158a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef876a29-298e-4be9-a84d-80030ee56623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10/799 items processed\n",
      "Progress: 20/799 items processed\n",
      "Progress: 30/799 items processed\n",
      "Progress: 40/799 items processed\n",
      "Progress: 50/799 items processed\n",
      "Progress: 60/799 items processed\n",
      "Progress: 70/799 items processed\n",
      "Progress: 80/799 items processed\n",
      "Progress: 90/799 items processed\n",
      "Progress: 100/799 items processed\n",
      "Progress: 110/799 items processed\n",
      "Progress: 120/799 items processed\n",
      "Progress: 130/799 items processed\n",
      "Progress: 140/799 items processed\n",
      "Progress: 150/799 items processed\n",
      "Progress: 160/799 items processed\n",
      "Progress: 170/799 items processed\n",
      "Progress: 180/799 items processed\n",
      "Progress: 190/799 items processed\n",
      "Progress: 200/799 items processed\n",
      "Progress: 210/799 items processed\n",
      "Progress: 220/799 items processed\n",
      "Progress: 230/799 items processed\n",
      "Progress: 240/799 items processed\n",
      "Progress: 250/799 items processed\n",
      "Progress: 260/799 items processed\n",
      "Progress: 270/799 items processed\n",
      "Progress: 280/799 items processed\n",
      "Progress: 290/799 items processed\n",
      "Progress: 300/799 items processed\n",
      "Progress: 310/799 items processed\n",
      "Progress: 320/799 items processed\n",
      "Progress: 330/799 items processed\n",
      "Progress: 340/799 items processed\n",
      "Progress: 350/799 items processed\n",
      "Progress: 360/799 items processed\n",
      "Progress: 370/799 items processed\n",
      "Progress: 380/799 items processed\n",
      "Progress: 390/799 items processed\n",
      "Progress: 400/799 items processed\n",
      "Progress: 410/799 items processed\n",
      "Progress: 420/799 items processed\n",
      "Error processing item 428: invalid syntax (<unknown>, line 7)\n",
      "Progress: 430/799 items processed\n",
      "Progress: 440/799 items processed\n",
      "Error processing item 441: invalid syntax (<unknown>, line 1)\n",
      "Progress: 450/799 items processed\n",
      "Progress: 460/799 items processed\n",
      "Progress: 470/799 items processed\n",
      "Progress: 480/799 items processed\n",
      "Progress: 490/799 items processed\n",
      "Progress: 500/799 items processed\n",
      "Progress: 510/799 items processed\n",
      "Progress: 520/799 items processed\n",
      "Progress: 530/799 items processed\n",
      "Progress: 540/799 items processed\n",
      "Progress: 550/799 items processed\n",
      "Error processing item 556: invalid syntax (<unknown>, line 2)\n",
      "Progress: 560/799 items processed\n",
      "Progress: 570/799 items processed\n",
      "Progress: 580/799 items processed\n",
      "Progress: 590/799 items processed\n",
      "Progress: 600/799 items processed\n",
      "Progress: 610/799 items processed\n",
      "Progress: 620/799 items processed\n",
      "Progress: 630/799 items processed\n",
      "Progress: 640/799 items processed\n",
      "Progress: 650/799 items processed\n",
      "Progress: 660/799 items processed\n",
      "Progress: 670/799 items processed\n",
      "Progress: 680/799 items processed\n",
      "Progress: 690/799 items processed\n",
      "Progress: 700/799 items processed\n",
      "Progress: 710/799 items processed\n",
      "Progress: 720/799 items processed\n",
      "Progress: 730/799 items processed\n",
      "Progress: 740/799 items processed\n",
      "Progress: 750/799 items processed\n",
      "Progress: 760/799 items processed\n",
      "Progress: 770/799 items processed\n",
      "Progress: 780/799 items processed\n",
      "Progress: 790/799 items processed\n",
      "Progress: 799/799 items processed\n",
      "\n",
      "Processing complete.\n",
      "Total items: 799\n",
      "Successful: 796\n",
      "Errors: 3\n"
     ]
    }
   ],
   "source": [
    "list_of_dicts=dataframe_batches(unique_listings)\n",
    "list_of_dicts = list_of_dicts[501:1300]\n",
    "result_df, errors_df = execute_keyword_LLM(list_of_dicts, chain)\n",
    "\n",
    "import os\n",
    "\n",
    "output_folder = 'output'\n",
    "file_name = 'mistral-nemo_10.csv'\n",
    "file_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    result_df.to_csv(file_path, mode='a', header=False, index=False)\n",
    "else:\n",
    "    result_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace553e-ceea-4f35-a60b-98ced5250fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
